{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyfaidx import Fasta \n",
    "\n",
    "#a helpful tip: in case you change your _config file while your notebook is running, \n",
    "#make sure to reload the _config module when you do, otherwise the variables will get stale\n",
    "import importlib\n",
    "import _config\n",
    "importlib.reload(_config)\n",
    "from _config import DATA_DIR, OUT_PLACE\n",
    "\n",
    "from _configpatterns import REGRESSION_TRACK_FILES, CONFIGURATION_NAME, ALL_TRACK_FILES\n",
    "from _configcompare import COMPARISON_FILES, CONFIGURATION_NAME \n",
    "\n",
    "#use your data directory to locate your data files\n",
    "JEN_DATA_DIR = os.path.join(DATA_DIR,\"jen\")\n",
    "COMPARE_DATA_DIR = os.path.join(DATA_DIR,\"shibata\")\n",
    "PATTERN_DATA_DIR = os.path.join(DATA_DIR,\"mouse\")\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw_eccdna\")\n",
    "NOREPEATS_DATA_DIR = os.path.join(DATA_DIR, \"no_repeats\")\n",
    "ENCODE_DATA_DIR = os.path.join(DATA_DIR, \"encode\")\n",
    "\n",
    "OUT_DIR = os.path.join(OUT_PLACE,\"eccdna1_firsttests\")\n",
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)\n",
    "    \n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [rtf['filename'] for rtf in REGRESSION_TRACK_FILES]\n",
    "allfiles = [rtf['filename'] for rtf in ALL_TRACK_FILES]\n",
    "filenames = [rtf['name'] for rtf in REGRESSION_TRACK_FILES]\n",
    "allfilenames = [rtf['name'] for rtf in ALL_TRACK_FILES]\n",
    "\n",
    "compare_files = [rtf['filename'] for rtf in COMPARISON_FILES]\n",
    "compare_names = [rtf['name'] for rtf in COMPARISON_FILES]\n",
    "\n",
    "allowed_chromosomes = [f'chr{x}' for x in (list(range(1,19)) + ['X', 'Y'])]\n",
    "targetshape = (21, 2000)\n",
    "zeros = np.zeros(targetshape)\n",
    "box_smoothing_window = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xvalue(x):\n",
    "    return 22 if 'X' in x else (23 if 'Y' in x else int(x[3:])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delimit(file):\n",
    "    for l in open(file):\n",
    "        delim = '\\t' if re.compile('\\t').search(l) else ','\n",
    "        break\n",
    "    return delim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_process(file):\n",
    "    big_array = np.zeros(targetshape)\n",
    "    pattern_path = os.path.join(PATTERN_DATA_DIR, file)\n",
    "    name = pd.read_csv(pattern_path, delimiter=delimit(pattern_path))\n",
    "    \n",
    "    name = name.loc[name.chrom.isin(allowed_chromosomes)]\n",
    "    name = name.rename(columns = {\"chrom\":\"Chr\",\"chromStart\":\"FeatureStart\",\"chromEnd\":\"FeatureEnd\"})\n",
    "    name['FeatureMid100k'] = (name[['FeatureStart', 'FeatureEnd']].mean(axis=1))//1e5\n",
    "    name_chromosome = pd.concat([name.Chr.apply(xvalue).rename('x'),\n",
    "                            name.FeatureMid100k.rename('y')], axis=1)\n",
    "    name_pixels = name_chromosome.groupby(['x','y']).apply(lambda x: x.y.count()) \n",
    "    \n",
    "    namehg_pixels = name_pixels.unstack().fillna(0).values\n",
    "    if namehg_pixels.size < 48000:\n",
    "        big_array[0:namehg_pixels.shape[0],0:namehg_pixels.shape[1]] = namehg_pixels\n",
    "        namehg_pixels = big_array\n",
    "    else:\n",
    "        namehg_pixels = namehg_pixels[0:big_array.shape[0],0:big_array.shape[1]]\n",
    "    return namehg_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_process(pixels):\n",
    "    pixels[pixels > 100] = 100\n",
    "    pixels_smooth = np.mean(np.array([np.roll(pixels,translation) \n",
    "                                       for translation in range(box_smoothing_window)]),0)\n",
    "    #how much to smooth by?\n",
    "    smooth_binary =1*(pixels_smooth > np.percentile(pixels_smooth,80))\n",
    "    return smooth_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(file):\n",
    "    return np.ndarray.flatten(file_process(file))\n",
    "\n",
    "def vectorize_all(files):\n",
    "    result = []\n",
    "    for file in files:\n",
    "        result.append(vectorize(file))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_compare(files, compare_t, transparency2):\n",
    "    data = pd.DataFrame(np.transpose(vectorize_all(files)+[np.ndarray.flatten(transparency2)]), columns = files + ['eccdna comparison'])\n",
    "    target = np.ndarray.flatten(compare_t)\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "    data_std = pd.DataFrame(data_std, columns = files + ['transparency'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.10)\n",
    "    return linear_model.ElasticNetCV().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(files, transparency2):\n",
    "    data = pd.DataFrame(np.transpose(vectorize_all(files)), columns = files)\n",
    "    target = np.ndarray.flatten(transparency2)\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "    data_std = pd.DataFrame(data_std, columns = files)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.10)\n",
    "    return linear_model.RidgeCV().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet(files, transparency2):\n",
    "    data = pd.DataFrame(np.transpose(vectorize_all(files)), columns = files)\n",
    "    target = np.ndarray.flatten(transparency2)\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "    data_std = pd.DataFrame(data_std, columns = files)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.10)\n",
    "    return linear_model.ElasticNetCV().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(files, transparency):\n",
    "    zeros = np.zeros(targetshape)\n",
    "    processed = []\n",
    "    for file in files:\n",
    "        if type(file) == np.ndarray:\n",
    "            processed.append(file)\n",
    "        else:\n",
    "            result = pixel_process(file_process(file))\n",
    "            processed.append(result)\n",
    "    while len(processed) < 3:\n",
    "        processed.append(zeros)\n",
    "    processed.append(transparency)\n",
    "    return np.array(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_hist(files):\n",
    "    labels = ['eccdna'] + ['raw eccdna'] + compare_names\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(10,8)\n",
    "    bins = np.linspace(0, 9000, 100)\n",
    "    for file in files:\n",
    "        plt.hist(file.length, bins, edgecolor='black', linewidth=1.2, alpha = 0.5, label = labels.pop(0))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('eccdna length in bp')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_regression_plot(transparency):\n",
    "    f , ax = plt.subplots(1, 2)\n",
    "    f.suptitle('Co-occurance of eccdna with various DNA patterns', y=1.0)\n",
    "    f.set_size_inches(20,8)\n",
    "    labels = [f\"chr{x}\" for x in (list(range(1,20)) + [\"X\",\"Y\"])]\n",
    "\n",
    "    imaget = np.array(process(files, transparency))\n",
    "    image = imaget.transpose([1,2,0])\n",
    "\n",
    "    plt.sca(ax[0])\n",
    "    ax[0].set_yticks(range(21))\n",
    "    ticks = ax[0].set_yticklabels(labels)\n",
    "    ax[0].set_title('Co-occurance of eccdna with all 3 DNA patterns')\n",
    "    im = plt.imshow(image, aspect = 'auto')\n",
    "\n",
    "    values = elasticnet(files, transparency).coef_\n",
    "#     values = ['%.2f' % elem for elem in values]\n",
    "    values = list(map(float, values))\n",
    "\n",
    "    color = ['red', 'green', 'blue']\n",
    "    df = np.transpose(pd.DataFrame(np.array([values, files, color])))\n",
    "    df = df.rename(columns = {0:'coef_value', 1:'dataset', 2:'color'})\n",
    "    df = df.sort_values(by='coef_value', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    plt.sca(ax[1])\n",
    "    plt.bar(list(range(1, len(df.dataset)+1)), [float(x) for x in df.coef_value], color = df.color)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Datasets sorted by coefficient calculation from Elastic Net Model')\n",
    "    ax.set_xticks(range(1, 4))\n",
    "    plt.ylim(bottom=0)\n",
    "    ticks = ax.set_xticklabels(df.dataset)\n",
    "    \n",
    "#     ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "#     labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "#     ax.set_yticklabels([str(round(float(label), 2)) for label in labels if label!=''])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_regression_compare_plot(compare_t, transparency):\n",
    "    f , ax = plt.subplots(1, 2)\n",
    "    f.suptitle('Co-occurance of eccdna with various DNA patterns', y=1.0)\n",
    "    f.set_size_inches(20,8)\n",
    "    labels = [f\"chr{x}\" for x in (list(range(1,20)) + [\"X\",\"Y\"])]\n",
    "\n",
    "    imaget = np.array(process(files, transparency))\n",
    "    image = imaget.transpose([1,2,0])\n",
    "\n",
    "    plt.sca(ax[0])\n",
    "    ax[0].set_yticks(range(21))\n",
    "    ticks = ax[0].set_yticklabels(labels)\n",
    "    ax[0].set_title('Co-occurance of eccdna with all 3 DNA patterns')\n",
    "    im = plt.imshow(image, aspect = 'auto')\n",
    "\n",
    "    values = elasticnet_compare(files, compare_t, transparency).coef_\n",
    "    values = ['%.2f' % elem for elem in values]\n",
    "    values = list(map(float, values))\n",
    "\n",
    "    color = ['red', 'green', 'blue', 'grey']\n",
    "    df = np.transpose(pd.DataFrame(np.array([values, (files + ['compare']), color])))\n",
    "    df = df.rename(columns = {0:'coef_value', 1:'dataset', 2:'color'})\n",
    "    df = df.sort_values(by='coef_value', ascending = False).reset_index(drop=True)\n",
    "    plt.sca(ax[1])\n",
    "    plt.bar(list(range(1, len(df.dataset)+1)), [float(x) for x in df.coef_value], color = df.color)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Datasets sorted by coefficient calculation from Elastic Net Model')\n",
    "    ax.set_xticks(range(1, 5))\n",
    "    plt.ylim(bottom=0)\n",
    "    ticks = ax.set_xticklabels(df.dataset)\n",
    "    \n",
    "#     ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "#     labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "#     ax.set_yticklabels([str(round(float(label), 2)) for label in labels if label!=''])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cor_plot(allfiles):\n",
    "    data = pd.DataFrame(np.transpose(vectorize_all(allfiles)), columns = allfiles).transpose()\n",
    "    corr = np.corrcoef(data)\n",
    "    fig = plt.figure()\n",
    "    labels = [x[5:-4] for x in data.index]\n",
    "    corrmap = sns.heatmap(corr, xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccdna_cor_plot(pixels):\n",
    "    flattened = []\n",
    "    for pixel in pixels:\n",
    "        flattened.append(np.ndarray.flatten(pixel_process(pixel)))\n",
    "        \n",
    "    data = pd.DataFrame(np.transpose(flattened), columns = ['eccdna', 'heart', 'liver', 'brain']).transpose()\n",
    "    corr = np.corrcoef(data)\n",
    "    fig = plt.figure()\n",
    "    labels = ['eccdna', 'heart', 'liver', 'brain']\n",
    "    corrmap = sns.heatmap(corr, xticklabels=labels, yticklabels=labels, cmap = 'plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pixelate(compare_df):\n",
    "    compare_df['mid100k'] = (compare_df[['start','end']].mean(axis = 1))//1e5\n",
    "    compare_array = pd.concat([compare_df.chrom.apply(xvalue).rename('x'), \n",
    "                       compare_df.mid100k.rename('y'), compare_df.abundance], axis = 1)\n",
    "    compare_array['abundance1'] = compare_array.groupby(['x', 'y']).transform('count')\n",
    "    compare_array['abundance'] = compare_array['abundance'] + compare_array['abundance1']\n",
    "    compare_array = compare_array.drop('abundance1', 1)\n",
    "    compare_array = compare_array.drop_duplicates(['x', 'y'])\n",
    "    return compare_array.pivot(index='x', columns='y', values='abundance').fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dfmaker(file):\n",
    "    compare_path = os.path.join(COMPARE_DATA_DIR, file)\n",
    "    compare_df = pd.read_csv(compare_path, delimiter=\"\\t\")\n",
    "    compare_df.columns = ['chrom','start','end','abundance','extra']\n",
    "    compare_df = compare_df.drop('extra',1)\n",
    "    compare_df['length'] = compare_df['end'] - compare_df['start']\n",
    "    return compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transparent(pixel):\n",
    "    transparency = (pixel).values\n",
    "    big_transparency = np.zeros(targetshape)\n",
    "    big_transparency[0:transparency.shape[0], 0:transparency.shape[1]] = transparency\n",
    "    return big_transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccdna_pixelate(loci):\n",
    "    loci['mid100k'] = (loci[['start','end']].mean(axis = 1))//1e5\n",
    "    loci_array = pd.concat([loci.chrom.apply(xvalue).rename('x'), \n",
    "                       loci.mid100k.rename('y')], axis = 1)\n",
    "    \n",
    "    return loci_array.groupby(['x', 'y']).apply(lambda x: x.y.count()).unstack().fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccdna_binary_plot(eccdna_t, compare_t):\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    f.suptitle('co-occurance of eccdna regions and particular shibata data', y=1.0)\n",
    "    f.set_size_inches(20,8)\n",
    "    labels = [f\"chr{x}\" for x in (list(range(1,20)) + [\"X\",\"Y\"])]\n",
    "    \n",
    "    imaget = np.array(process([zeros, compare_t, zeros], eccdna_t))\n",
    "    image = imaget.transpose([1,2,0])\n",
    "    \n",
    "    ax.set_yticks(range(21))\n",
    "    ticks = ax.set_yticklabels(labels)\n",
    "#     ax.set_title('Co-occurance of eccdna')\n",
    "    plt.imshow(image, aspect = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features_plot(dna_trans, feature_files):\n",
    "    #figure out how to add the name of the dna in the title -_-\n",
    "    #just copied everything in here, needs to be cleaned up - this function does not work lol\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    f.suptitle('Features sorted by coefficient calculation based on Elastic Net Model', y=1.0)\n",
    "    f.set_size_inches(20,8)\n",
    "    \n",
    "    values = ridge(feature_files, dna_trans).coef_\n",
    "    values = list(map(float, values))\n",
    "\n",
    "    df = np.transpose(pd.DataFrame(np.array([values, allfilenames])))\n",
    "    df = df.rename(columns = {0:'coef_value', 1:'dataset'})\n",
    "    df = df.sort_values(by='coef_value', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    plt.sca(ax)\n",
    "    plt.bar(list(range(1, len(df.dataset)+1)), [float(x) for x in df.coef_value])\n",
    "    ax.set_xticks(range(1, len(df.dataset)+1))\n",
    "    plt.ylim(bottom=0)\n",
    "    ticks = ax.set_xticklabels(df.dataset)\n",
    "    \n",
    "#     ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "#     labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "#     ax.set_yticklabels([str(round(float(label), 2)) for label in labels if label!=''])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccdna_scatter_plot():\n",
    "    ES_path = os.path.join(NOREPEATS_DATA_DIR, \"ES-1_norepeats.bed\")\n",
    "    ES_loci = pd.read_csv(ES_path, names = [\"chrom\", \"start\", \"end\", \"strand\", \"event_name\", \n",
    "                                            \"chrom2\", \"discordant reads\"], delimiter = \"\\t\")  \n",
    "    ES_loci['length'] = ES_loci['end'] - ES_loci['start']\n",
    "    ES_loci['mid100k'] = (ES_loci[['start','end']].mean(axis = 1))//1e5\n",
    "    loci_df = pd.concat([ES_loci.chrom.apply(xvalue).rename('x'), \n",
    "                           ES_loci.mid100k.rename('y')], axis = 1)\n",
    "\n",
    "    loci_df = loci_df.groupby([\"x\", \"y\"]).apply(lambda x: x.y.count())\n",
    "    loci_df = loci_df.reset_index(name=\"count\")\n",
    "    #loci_df has an x (chrom), y (bin) and count column\n",
    "\n",
    "    raw_path = os.path.join(NOREPEATS_DATA_DIR, \"MN-1_norepeats.bed\")\n",
    "    raw_loci = pd.read_csv(raw_path, names = [\"chrom\", \"start\", \"end\", \"strand\", \"event_name\", \n",
    "                                              \"chrom2\", \"discordant reads\"], delimiter = \"\\t\")\n",
    "    raw_loci['length'] = raw_loci['end'] - raw_loci['start']\n",
    "    raw_loci['mid100k'] = (raw_loci[['start','end']].mean(axis = 1))//1e5\n",
    "    raw_df = pd.concat([raw_loci.chrom.apply(xvalue).rename('x'), \n",
    "                           raw_loci.mid100k.rename('y')], axis = 1)\n",
    "    MN_df = raw_df.groupby([\"x\", \"y\"]).apply(lambda x: x.y.count())\n",
    "    MN_df = MN_df.reset_index(name=\"count2\")\n",
    "    #MN_df has an x (chrom), y (bin) and count column\n",
    "\n",
    "    s1 = pd.merge(MN_df, loci_df, how='left', on=['x', 'y']).fillna(0)\n",
    "    \n",
    "    f = plt.figure()\n",
    "    plt.scatter(s1['count'], s1['count2'])\n",
    "    plt.xlabel('Number of unique ES eccdnas at a particular bin')\n",
    "    plt.ylabel('Number of unique MN eccdnas at a particular bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_processdata(data):\n",
    "    fpath = os.path.join(ENCODE_DATA_DIR, data)\n",
    "    loci = pd.read_csv(fpath, names = [\"chrom\", \"start\", \"end\", \"name\", \"score\",\"strand\", \"sigval\",\n",
    "                                      \"pval\", \"qval\"], delimiter = \"\\t\")\n",
    "    loci[\"length\"] = loci[\"end\"] - loci[\"start\"]\n",
    "    loci[\"chrom\"] = loci.chrom.apply(xvalue)\n",
    "    loci[\"bin\"] = (loci[[\"start\",\"end\"]].mean(axis = 1))//1e5\n",
    "    loci = loci.groupby([\"chrom\", \"bin\"]).apply(lambda x: x.length.sum()/1e3) #gives percentages\n",
    "    loci = loci.reset_index(name = \"percent_cov\")\n",
    "    return loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_plot():\n",
    "    MN = encode_processdata(\"MN_ENCFF840MRT.bed\")\n",
    "    ES = encode_processdata(\"ES_ENCFF319IPQ.bed\")\n",
    "\n",
    "#     ES = ES.iloc[0:(ES[ES.chrom == 1].index[0])]\n",
    "#     MN = MN.iloc[0:(MN[MN.chrom == 1].index[0])]\n",
    "    \n",
    "    for chrom, ES_chrom in ES.groupby('chrom'):\n",
    "        if chrom == 5:\n",
    "            break\n",
    "        MN_chrom = MN.iloc[(MN[MN.chrom==chrom].index[0]):(MN[MN.chrom==chrom+1].index[0])]\n",
    "        f = plt.figure()\n",
    "        f.suptitle(\"Chromosome \" + str(chrom+1) + \" DNase-seq comparison between MN and ES mm10\", \n",
    "                   y=0.95, fontsize=16)\n",
    "        f.set_size_inches(20,8)\n",
    "        plt.bar(MN_chrom.bin, MN_chrom.percent_cov, color='b', alpha = 0.5, label='MN')\n",
    "        plt.bar(ES_chrom.bin, ES_chrom.percent_cov, color='r', alpha=0.5, label='ES')\n",
    "        plt.xlabel(\"100kbp bins\", fontsize = 14)\n",
    "        plt.ylabel(\"percentage of bin covered by DNase-seq peaks (open chromatin)\", fontsize=14)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        ax.set_facecolor(\"white\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure(tracks, eccdna, raw_eccdna, compare_files):\n",
    "    with PdfPages(os.path.join(OUT_DIR,\"eccdna1_figures_\"+CONFIGURATION_NAME+'.pdf')) as pdf:\n",
    "    \n",
    "        #Jen's eccdna data\n",
    "        fpath = os.path.join(JEN_DATA_DIR, eccdna)\n",
    "        loci = pd.read_csv(fpath, names = [\"chrom\",\"start\",\"end\"], delimiter=\"\\t\")\n",
    "        loci['length'] = loci['end'] - loci['start']\n",
    "        pixels = eccdna_pixelate(loci)\n",
    "        transparency = transparent(pixels)\n",
    "        \n",
    "        # map_regression_plot(transparency)\n",
    "        # all_features_plot(transparency, allfiles)\n",
    "    \n",
    "    \n",
    "        #Jen's raw eccdna data\n",
    "        raw_path = os.path.join(RAW_DATA_DIR, raw_eccdna)\n",
    "        raw_loci = pd.read_csv(raw_path, names = [\"chrom\", \"start\", \"end\", \"strand\", \"event_name\", \n",
    "                                                  \"chrom2\", \"discordant reads\"], delimiter = \"\\t\")\n",
    "        raw_loci['length'] = raw_loci['end'] - raw_loci['start']\n",
    "        raw_eccdna_pixels = eccdna_pixelate(raw_loci)\n",
    "        raw_transparency = transparent(pixels)\n",
    "        #2000 might be too small - but no error so far\n",
    "        # map_regression_plot(raw_transparency)\n",
    "        # all_features_plot(raw_transparency, allfiles)\n",
    "        \n",
    "        #raw data scatter plot: repeats haven't been removed yet because I'm confused...\n",
    "        ES_path = os.path.join(RAW_DATA_DIR, \"ES-1.bed\")\n",
    "        ES_loci = pd.read_csv(ES_path, names = [\"chrom\", \"start\", \"end\", \"strand\", \"event_name\", \n",
    "                                                  \"chrom2\", \"discordant reads\"], delimiter = \"\\t\")\n",
    "        ES_loci['length'] = ES_loci['end'] - ES_loci['start']\n",
    "        ES_eccdna_pixels = eccdna_pixelate(ES_loci)\n",
    "        #what is the datatype of ES_eccdna_pixels?\n",
    "        eccdna_scatter_plot()\n",
    "        encode_plot()\n",
    "        \n",
    "        \n",
    "        #pixel and file accumulators\n",
    "        correlate_data = [transparency]\n",
    "        #length_hist_data = [loci, raw_loci]\n",
    "        length_hist([loci])\n",
    "        length_hist([raw_loci])\n",
    "        \n",
    "        \n",
    "        #Shibata comparison data\n",
    "        for compare in compare_files:\n",
    "            compare_file = compare_dfmaker(compare)\n",
    "            \n",
    "            #length_hist_data.append(compare_file)\n",
    "            \n",
    "            compare_pixels = compare_pixelate(compare_file)\n",
    "            compare_transparency = transparent(compare_pixels)\n",
    "            \n",
    "            correlate_data.append(compare_transparency)\n",
    "            length_hist([compare_file])\n",
    "            # all_features_plot(compare_transparency, allfiles)\n",
    "            \n",
    "#             pdf.savefig(eccdna_binary_plot(transparency, compare_transparency))\n",
    "#             pdf.savefig(map_regression_plot(compare_transparency))\n",
    "        \n",
    "#         pdf.savefig(eccdna_cor_plot(correlate_data))\n",
    "        # length_hist(length_hist_data)\n",
    "#         pdf.savefig(feature_cor_plot(allfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(REGRESSION_TRACK_FILES, \"mid_conf_MN-de.bed\", \"MN-1.bed\", compare_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# notice that there are several eccdna files to choose from:\n",
    "# [high_conf.bed  high_conf_MN-de.bed  low_conf.bed  low_conf_MN-de.bed  mid_conf.bed  mid_conf_MN-de.bed]\n",
    "## \n",
    "\n",
    "#I am loading high confidence Motor Neuron (MN) dnas here:\n",
    "fpath = os.path.join(JEN_DATA_DIR, \"high_conf_MN-de.bed\")\n",
    "loci = pd.read_csv(fpath, names = [\"chrom\",\"start\",\"end\"],delimiter=\"\\t\")\n",
    "\n",
    "#But you can try the mid_conf_MN-de.bed file too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the rest is all up to your imagination :)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
